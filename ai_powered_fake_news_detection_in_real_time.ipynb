{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Indhupamula/ai-powered-fake-news-detector/blob/main/ai_powered_fake_news_detection_in_real_time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBSRAoTKSMxn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV files\n",
        "fake = pd.read_csv(\"Fake.csv\")\n",
        "true = pd.read_csv(\"True.csv\")\n",
        "\n",
        "# Add labels\n",
        "fake['label'] = 'Fake'\n",
        "true['label'] = 'Real'\n",
        "\n",
        "# Combine and shuffle\n",
        "data = pd.concat([fake, true])\n",
        "data = pd.concat([fake, true]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Keep only the columns we need\n",
        "data = data[['text', 'label']]\n",
        "\n",
        "# Preview first few rows\n",
        "data.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a text cleaning function\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()                  # Convert to lowercase\n",
        "    text = re.sub(r'\\W', ' ', text)           # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)          # Remove extra whitespace\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning to all text entries\n",
        "data['text'] = data['text'].apply(clean_text)\n",
        "\n",
        "# Preview cleaned data\n",
        "data.head()\n",
        "data['label'].value_counts()\n",
        "\n"
      ],
      "metadata": {
        "id": "4f86ua5jgH-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLIzQTFvM3E1"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    max_df=0.7,\n",
        "    min_df=3,               # Remove very rare words\n",
        "    ngram_range=(1, 3),     # Include unigrams, bigrams, trigrams\n",
        "    sublinear_tf=True       # Normalize term frequency\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(data['text'])\n",
        "y = data['label']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Split into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "9SjUorengzF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Show accuracy\n",
        "print(f\" Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "smIr7N5wg3qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classes_\n"
      ],
      "metadata": {
        "id": "I0nWAFyRlxuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_news_debug(text):\n",
        "    cleaned = clean_text(text)\n",
        "    vec = vectorizer.transform([cleaned])\n",
        "    probs = model.predict_proba(vec)[0]\n",
        "    return {\n",
        "        'Fake': f\"{probs[model.classes_.tolist().index('Fake')]*100:.2f}%\",\n",
        "        'Real': f\"{probs[model.classes_.tolist().index('Real')]*100:.2f}%\"\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ahXq24CBh0nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_news_debug(data[data['label'] == 'Real'].iloc[10]['text'])\n"
      ],
      "metadata": {
        "id": "7EV9QxaZogqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Prediction function\n",
        "def predict_news_bert(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]\n",
        "    labels = [\"Fake\", \"Real\"]\n",
        "    pred_index = torch.argmax(probs).item()\n",
        "    confidence = probs[pred_index].item() * 100\n",
        "    return f\"ðŸ“° Prediction: {labels[pred_index]} ({confidence:.2f}% confidence)\"\n",
        "\n",
        "# Gradio UI\n",
        "demo = gr.Interface(\n",
        "    fn=predict_news_bert,\n",
        "    inputs=gr.Textbox(lines=8, placeholder=\"Paste news article here...\", label=\"News Article\"),\n",
        "    outputs=gr.Textbox(label=\"Prediction\"),\n",
        "    title=\"ðŸ§  BERT Powered Fake News Detector\",\n",
        "    description=\"Paste any news article to check whether it's Fake or Real using a BERT model.\"\n",
        ")\n",
        "\n",
        "# Launch\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "C0tqd61AvzWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "id": "yJdFmFVmy2s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create project folder and go inside it\n",
        "!mkdir FakeNewsApp\n",
        "%cd FakeNewsApp\n",
        "\n",
        "# Create app.py with your BERT + Gradio code\n",
        "app_code = \"\"\"\n",
        "import gradio as gr\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "def predict_news_bert(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]\n",
        "    labels = [\"Fake\", \"Real\"]\n",
        "    pred_index = torch.argmax(probs).item()\n",
        "    confidence = probs[pred_index].item() * 100\n",
        "    return f\"ðŸ“° Prediction: {labels[pred_index]} ({confidence:.2f}% confidence)\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_news_bert,\n",
        "    inputs=gr.Textbox(lines=8, label=\"News Article\"),\n",
        "    outputs=gr.Textbox(label=\"Prediction\"),\n",
        "    title=\" BERT Fake News Detector\",\n",
        "    description=\"Paste a news article and find out if it's Fake or Real using BERT!\"\n",
        ")\n",
        "\n",
        "demo.launch()\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# Create requirements.txt\n",
        "with open(\"requirements.txt\", \"w\") as f:\n",
        "    f.write(\"gradio\\ntransformers\\ntorch\\n\")\n"
      ],
      "metadata": {
        "id": "bOzfD29OzeCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# âœ… This is your actual space ID\n",
        "repo_id = \"indhupamula/fake-news-bert-indhu\"\n",
        "\n",
        "# Upload app.py\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/FakeNewsApp/app.py\",\n",
        "    path_in_repo=\"app.py\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"space\"\n",
        ")\n",
        "\n",
        "# Upload requirements.txt\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/FakeNewsApp/requirements.txt\",\n",
        "    path_in_repo=\"requirements.txt\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"space\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "XZWFHfY40tNh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4yybG37JhCI98GxyBfNiS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}